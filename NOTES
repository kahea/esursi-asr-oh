
BACKGROUND KNOWLEDGE

  Terms
    orthogonal - perpedicular (line, segments, planes)
    vectors orthogonal if inner product equal to 0

  Advanced Calculus
  Linear Algebra
  Matrix Theory

  Linear System
    y = ·∂≤(m x n matrix acting on Euclidean space aka linear operator on a Hilbert space) x

    vector x is a signal or input
    ·∂≤ the transform-sample matrix-filter
    vector y the sample or output

    problem is to reconstruct x from y aka reconstruct an altered version of x from an altered y
      i.e. analyze signal in terms of frequency components and various combinations of time & frequency components y

    may alter some component parts to eeliminate undesirable features or to compress

    Analysis - decompose

    Processing - transform

    Synthesis - reconstruct

    invertible (Fourier)
    undetermined (bandlimited functions, windowed Fourier transform, frames) - unique solution can only be obtained if x is restricted
    overdetermined (filter banks) - can throw soem information away from y and still recover x
    collection Euclidean space

    Vector Space - a linear space of objects closed (stay is same set) under associative, distributive and commutative laws.

      Span -> a linear space may be generated from a smaller collection of its members by linear combinations
        intersection of all subspaces containing the set
        if S if finite, set of all linear combinations of the elements of S

      dot poduct - angle between two vectors (formalized by the notion of inner product)

      subspace - nonempty set closed under addition and scalar multiplication

      norm of a vector x
        ||x|| = sqrroot(<x,x>) = sqroot(x¬≤‚ÇÄ + x¬≤‚ÇÅ)

      unit vector - vector of norm 1

      distance between two vecotrs
        d(x,y) = ||x-y|| = sqroot(<x -y, x - y>) = sqroot((x‚ÇÄ - y‚ÇÄ)¬≤ + (x‚ÇÅ - y‚ÇÅ)¬≤)

      orthogonality (pg 25@46 Vertelli)

      standard basis (orthonormal - orthogonal and unit norm) any orthonormal basis has a dual
        ùëí‚ÇÄ = [1, 0]·µÄ, ùëí‚ÇÅ = [0, 1]·µÄ     aka i & j
        {ùëí‚ÇÄ, ùëí‚ÇÅ}
        <x,y> = 0 & <x,x> = 1

      linearly independent - 0 vector only if a‚Çñ = 0 for all k

      Inner Product (scalar product, dot product)
        - preserves the concept of 'perpendicular/orthonormal' or 'shortest distance'
        - normed linear space satisfying a parallelogram law
        - measures norms and similarities of vectors

        <x,y> = x‚ÇÄy‚ÇÄ + x‚ÇÅy‚ÇÅ
              = ||x|| ||y|| cos(‚ç¨‚Çì - ‚ç¨y)

        antiparallel when ‚ç¨ = œÄ

        orthogonal/perpendicular when <x,y> = 0



    Completeness
      - closed under limiting proceses

    Hilbert Space 
      - complete inner product space

      ‚ÑÇ·¥∫

      ùìµ¬≤(‚Ñ§) - square-summable sequences
        inner product
          ‚ü®ùë•,y‚ü© = ‚àë‚Çô ùë•‚Çôùë¶*‚Çô

      ùìõ¬≤(‚Ñù) - square-integrable functions
        inner product
          ‚ü®ùë•,y‚ü© = ‚à´ ùë•(ùë°)ùë¶(ùë°)* ùëëùë°

    Basis
      - a spanning set which is linearly independent

    V (vector space aka linear space)
    F (field) is R(REAL) or C(COMPLEX)
    elements of F called scalars
    u, v, c are vectors
    a, b are scalars

    V over fields F capture properties of n >= 1 Euclidean space V‚Åø which is the space of all
    R‚Åø or C‚Åø column vectors with n entries closed under addition and scalar multiplication

    axioms - associativity, commutativity, identity, inverse, compatibility, distributivity

    linear combination of x, y = ax + by

    nonempty W in V is a subspace of V if au + bv ‚àà W for all a,b ‚àà F and u, v ‚àà W

    Linear combination of vectors

OBJECTIVE
  classify contiguous signal as
   phoneme -> words -> sentences

TERMS

  Filter Bank
  LPC - Linear predictive coding

  Short Time - sound analysis based out short times. (stationary aspects of speech)

PROBLEMS
  
  coarticulation

    when words share a phoneme with previous word

SPEECH ACOUSTICS

  classification of speech sounds.
    characterize in terms of broad acoustic features whose properties relatively invariant across words and speakers

  speech signal is a slowly time varying singal
    when examined over sufficiently short periods of time (5-100 msec) it's characteristics are fairly stationary

    this breaks down at around (1/5 second or more)

  spectral representation - spectrogram
    intenisty in different frequency bands over time

    wideband 
      15msec sections
      125 Hz analysis
      1 msec intervals

    narrowband
      50msec sections
      40 Hz analysis
      1 msec intervals

    voiced regions - pitch are almost-horizontal lines
    unvoiced - high frequency energy
    silence - almost nothing (reduced signal level)

    formants - natural frequencies of the resonance tube (vocal tract)
      frequencies that pass the most acoustic energy

      signifigant for vocal tract three below 3500Hz

      diificult to get reliably for low-level voiced sounds and unvoiced or silence regions

      frequency for different vowells vary greatly between different speakers

      F1-F2 plane, vowell triangle

  phone/phoneme representations

    vowells (periodic)
      not very important in written text but in SR they are very important
      fixed acoustic shape

    dipthong
      gliding monosyllabic speecch
      starts near one vowell ends with another
      measure as plot F1-F2 formants over time. time-varying vocal tract area function

    semi-vowells /w/, /l/, /r/, /y/
      difficult to characterize
      generally gliding transition between adjacent phonemes
       thus acoustic characteristics are strongly influenced by context

    consonants (aperiodic)

    nasal consonants /m/, /n/, /nj/
      look similar

    unvoiced fricatives /f/, /theta/, /s/, /sh/
      steady air flow -> turbulent in region of constriction

    voiced fricatives /v/, /th/, /z/ /zh/

    stops /b/, /d/, /g/
      build then release

APPROACHES
  Approach 1 - acoustic-phonetic approach using sequential detection

    classify signal as in different states
      silence (S)
      unvoiced (U)
      voiced (V)

      difficult to distinguish say /f/ or /th/ from silence
      weak voiced sound /v/ or /m/ from unvoiced or silence

    step 1
      segmentation & labeling (hard to get accurate)
        segment into discrete time regions
        label as one or more potential phonemes

        uses training data

      word recognition
        reconstruct labels into a valid word


    speach analysis (filter bank) -> 
    feature detection -> 
      formants, pitch, voiced/unvoiced, energy, nasality, frication
    segmentation & labeling 
      phoneme lattice, segment lattice, probabilistic labeling, decision tree, parsing strategy
    control strategy

    segmentation
      find stable regions (where features change very little)

    pg 47. vowel classifier

    drawbacks
      no well defined automatic tuning procedure (i.e. adjusting descision thresholds)
      (not evel uniformly agreed upon way to label trainig speech by experts)

  Approach 2 - pattern-recognition
    speech is 'learned' via a training phase

    advantages/disadvantages
      simplicity
      robustness and invariance to different speech aspects (vocabs, users, features)
        used for a wide range of speech units (phoneme, word, word phrases, sentence)
      proven performance

      sensitive to amount of training data available (usually more the better)

      reference patterns are sensitive to speaking environment

      no speech-specific knowledge used - relatively insensitive to vocab, task, syntax, semantics

      computational load for training and classification in generally linearly proportional to number of patterns trained or recognized. computation can become prohibitive

      system is relatively insensitive to sound class making it applicable to a wide range of speech sounds/phrases/words/subwords/sentences

      relatively straitforward to incorporate syntactic/semantic constraints


    step 1 - define the test pattern
      feature measurements output of spectral analysis (filter bank, linear predictive coding, discrete fourier transform)

    step 2 - pattern training (creates reference pattern)
      one or more test patterns corresponding to speech sounds
      can be result of an exemplar, resultof an averaging technique, a model that charcterizes the features of a pattern
      spectral distance & global alignment (dynamic time warping)

    step 3 - pattern classification
      compute simliarity between test pattern and reference pattern

    step 4 - decision logic
      decide which pattern or sequence of patterns best matches unkown test pattern

  Approach 3 - AI
  combination of acoustic-phonetic and pattern-recognition

  pg 55 different models

  inncluding combined knowledged
    acoustic, lexical, syntatic, semantic, pragmatic

  Key Concepts
    Learning
    Adaptation

  submethod 1 - Neural Network
    could represent seperate approach or be combined with any of the above approaches

    dense interconnection parallel distributed computational elements

    pg 57

    for example inputs to a multilayer perceptron are F1 & F2 map a set of decsions to 10 steady state vowels. classifying on a hyper plane

    advantages
      massively parallel
      robust least sensitive to noise
      connections can adapt
      sufficiently large newtork can approximate any nonlinearity or nonlinear dynamic system

    to adapt to dynamic pattern of speech
      time delay neural network
      input to each element includes N speech frames

  Common Steps
    
    Speech Analysis
      Filter bank methods and linear predictive coding (LPC) methods (spectral descriptions)

    Feature Extraction
      formants, pitch, voiced/unvoiced, energy, nasality, frication

    Segmentation

    Steps

      acoustic-phonetic pg 71
        pattern measurement

      pattern-recognition
        pattern measurement
        pattern comparison
        decision making

SIGNAL PROCESSING aka SPECTRAL ANALYSIS (Front End)

  filter bank, LPC, [cochlea mechanics modeling]

  short time spectral envelope

  vector quantization - encoding a continous spectral representation by a 'typical' spectral shape

  Q bandpass filters

  s(n) passes through band of Q bandpass finter covering frequency range
    individual filters can do do overlap in frequency

  X‚Çô(e‚Å±·µÇ‚Å±)
  w·µ¢ = 2œÄf·µ¢/F‚Çõ
  F‚Çõ is the sampling frequency

  short time spectral representation of signal s(n) at time n as seen through ith bandpass filter

  representations -> frequency spectrum

  Filters

  bandpass -> nonlinear -> lowpass -> sampling rate reduction -> amplitude compression

    bandpass - reject anything that is not speech

    lowpass - filter out noice

    sampling rate reduction - resampled at 40-6- Hz (economy of representation)

    amplitue compression - compress bit-rate

  Implementations

    Fourier analyis - every complex wave can be represented as a sum of many sine waves of different frequencies


    infinite impulse response (IIR) (recursive filters)

    finite impulse response (FIR)
      - finite number of the coefficients hn are nonzero
      short-time Fourier transform

      casual - it doesn't respond to a signal until the signal is received

      2day moving average    y(1)(n) = 1/2(x(n) + x(n-1))
      2day moving difference y(2)(n) = 1/2(x(n) - x(n-1))
      xday moving average    y(3)(n) = 1/x k=0Ex-1 x(n-k) 

    Discrete-time Fourier transform (pg 235 Damelin)

      X(w) = n=-‚àû‚àë‚àû x‚Çôe‚Åª‚Å±‚Åø ∑

      input is the set of coefficients {x‚Çô}
      output is the 2œÄ-periodic function X(w) E L2 [-œÄ, œÄ]


  Vector Quantification (pg79 Rabiner)

    goal
      - compression without loss of 

    advantages
      - reduced storage
      - reduced computation
      - discrete representation of speech sounds

    disadvantages
      - quantization errors
      - trade off between quantization errors, processing and storage

    implementation needs
      - large set of spectral analysis vectors from a training set
      - similarity/distance between pairs of spectral analysis vectors among training sets
      - partition training vectors into M clusters (centroid computation procedure)
      - classification procedure for arbitrary speech

TRAINING
  
  determine domain of speech
    (talkers, age, accent, gender, speaking rate, background noise, input system(mics,..), vocabularies)

    the more narrow focused the smaller the error rate

  Vector Quantization
    need:
      compare distance between vectors

    partitioning:
      design a 1-vector codebook, then double it's size by splitting it

MATCHING

DECISION MAKING

PROJECT TASKS

  View Waveform
    [ ] load a .wav file
    [ ] display a wav in chart

  Transform and View Waveform using library
    [ ] perform transformations (use a library) T on .wav:
    [ ] display transformations in chart

  Transform and View Waveform using your own transform algorithm
    [ ] perform transformations with your on code on .wav:
    [ ] display transformation in chart

--------------------------------------------------------------------------------------------
Understanding Digital Signal Processing 
--------------------------------------------------------------------------------------------

contiguous-time signal
  ex. ùë•(ùë°) = sin(2œÄùëì‚ÇÄùë°)     an angle measured in radians
    ùë° independent variable continous time

discrete-time signal (DTS)
  - model of a contiguous signal
  - independent time variable is quantized defined by index ùëõ

  ex. ùë•(ùëõ) = sin(2œÄùëì‚ÇÄùëõùë°‚Çõ)
    ùëõùë°‚Çõ independent variable discrete-time
    ùë°‚Çõ sample period
    ùëì‚Çõ = 1/ùë°‚Çõ

frequency domain
  ùëã·µ¢(ùëö)
  - peak amplitude of each frequency

amplitude 
  - how far and in what direction the variable differs from zero

magnitude (absolute value) 
  |ùë•‚ÇÅ(ùëõ)| bars denote magnitude
  - how far regardless of direction the variaable differs from zero (always positive)

power
   = |ùë•‚ÇÅ(ùëõ)|¬≤
  - amplitude (or magnitude) squared
  - moderatley different amplitudes can have much larger relative powers

LTI - linear time invariant
  - commutative
  - 'unit impulse response' - time-domain ouput sequence when the input is a single unity-valued sample preceded and followed by zero-valued samplse
  - 'frequency response' - take Fourier transform (DFT) of impluse response

linear
  - output is the sum of the outputs of it's parts

time-invariant
  - delay in the input causes equivalent time delay in output

Discrete Fourier Transform (DFT)
  - used to determine harmonic, or frequency content of a DTS

  exponential form
    X(m) = n=0 ‚àë N-1 ( x(n)e ^(-j2œÄnm/N) )

    e is base of natural logarithms
    j (*sometimes i) = sqroot(-1)    

  rectangular form
    X(m) = n=0 ‚àë N-1 ( x(n)[cos(2œÄnm/N) - j sin(2œÄnm/N)] )

  X(m) = the mth DFT output component
     m = the index of the DFT output in the frequency domain
  x(n) = the sequence of input samples
     n = the time-domain index
     j = sqroot(-1)
     N = number of samples of input sequence and number of frequency points in the DFT


  X(0) = x(0)cos(2œÄ * 0 * 0 / 4) - jx(0)sin(2œÄ * 0 * 0 / 4)
       + x(1)cos(2œÄ * 1 * 0 / 4) - jx(1)sin(2œÄ * 1 * 0 / 4)
       + x(2)cos(2œÄ * 2 * 0 / 4) - jx(2)sin(2œÄ * 2 * 0 / 4)
       + x(3)cos(2œÄ * 3 * 0 / 4) - jx(3)sin(2œÄ * 3 * 0 / 4)

  X(1) = x(0)cos(2œÄ * 0 * 1 / 4) - jx(0)sin(2œÄ * 0 * 1 / 4)
       + x(1)cos(2œÄ * 1 * 1 / 4) - jx(1)sin(2œÄ * 1 * 1 / 4)
       + x(2)cos(2œÄ * 2 * 1 / 4) - jx(2)sin(2œÄ * 2 * 1 / 4)
       + x(3)cos(2œÄ * 3 * 1 / 4) - jx(3)sin(2œÄ * 3 * 1 / 4)

  each X(m) output is the sum of the point-for-point product between an input sequence of signal values and a complex sinusoid of the form cos(‚àÖ) - jsin(‚àÖ)

  fundamental fequence of sinusoids is ùëì‚Çõ/N = samples per second / points

--------------------------------------------------------------------------------------------
Fourier Transformations
--------------------------------------------------------------------------------------------

sine
  opposite / hypotenuse
  adjacent / hypotenuse

  sin(x) = cos(90 -x)
  cos(x) = sin(90 -x)

angular frequency
  w = 2œÄv
  v = frequency in Hz

T = periond of the function f(t)

w = 0, 2œÄ/T, 4œÄ/T, 6œÄ/T

any periodic function can be represented as a superposition of sine-function and cosine-function with appropriate amplitudes

ùëñ = ‚àö-1

e‚Å±À£ = cos(x) + ùëñsin(x)


compare with N sinusoidal basis waveforms

  dft analysis basis function

correlation
  how strongly present one signal is in another

magnitude is a measure of correlation


--------------------------------------------------------------------------------------------
Sound Waves
--------------------------------------------------------------------------------------------

compression
  high pressure within longitudinal wave
  particles to bunch together, increase density and pressure

rarefaction
  low pressure within longitudinal wave
  particles to move appart, decreases density and pressure

--------------------------------------------------------------------------------------------
Presentation
--------------------------------------------------------------------------------------------

play sounds of different frequencies ask audience if they can hear it


--------------------------------------------------------------------------------------------
Short-time speech analysis
--------------------------------------------------------------------------------------------
phoneme duration ~ 80ms
long vowells - up to 100ms
rapid events (stop releases) - 5-10ms

Windowing - multiplication of speech signal s(n) by a window w(n) yields a set of speech 
samples x(n) weighted by the shape of the window w(n).




--------------------------------------------------------------------------------------------
Signal Processing
--------------------------------------------------------------------------------------------

DFT

FFT

Hamming Window

[Filters]

[Cepstral analysis]


--------------------------------------------------------------------------------------------
Acoustic Modeling
--------------------------------------------------------------------------------------------


--------------------------------------------------------------------------------------------
Language Modeling
--------------------------------------------------------------------------------------------

